# Basic
* https://ruder.io/optimizing-gradient-descent/index.html
* https://cs231n.github.io/neural-networks-3/

# DL Theory
* http://people.csail.mit.edu/moitra/408b.html
* https://boazbk.github.io/mltheoryseminar/cs229br
* http://mitliagkas.github.io/ift6085-dl-theory-class/
* https://omrikaduri.github.io/2021/10/25/DL-Optimization-Introduction.html
* https://omrikaduri.github.io/2022/04/02/Deep-Learning-Optimization-Theory-Trajectory-Analysis-of-Gradient-Descent.html

# References
* https://medium.com/konvergen/finding-the-minimum-escaping-saddle-points-cd4be699933e
* https://towardsdatascience.com/an-intuitive-understanding-of-the-lamb-optimizer-46f8c0ae4866


* https://www.fast.ai/posts/2018-07-02-adam-weight-decay.html